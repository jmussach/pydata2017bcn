{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Visualization\n",
    "\n",
    "In this part weâ€™ll see how to create a simple but wrong model with Keras, and, gradually, how it can be improved with step-by-step debugging and understanding with TensorBoard.\n",
    "\n",
    "*Please, download [log files](https://drive.google.com/open?id=0B6VSPXOeu5J0TnRhS18xS2pBMFU) first.*\n",
    "\n",
    "Let's start from importing all necessary components/layers for the future CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Convolution2D, BatchNormalization, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from settings import *\n",
    "# from somethere import train_generator, val_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy convolutional model for classification\n",
    "First, we create a skeleton for a model with one convolutional and one dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(n_classes):\n",
    "\n",
    "    input_shape = (N_MEL_BANDS, SEGMENT_DUR, 1)\n",
    "    channel_axis = 3\n",
    "    melgram_input = Input(shape=input_shape)\n",
    "\n",
    "    m_size = 70\n",
    "    n_size = 3\n",
    "    n_filters = 64\n",
    "    maxpool_const = 4\n",
    "\n",
    "    x = Convolution2D(n_filters, (m_size, n_size),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='zeros',\n",
    "                      kernel_regularizer=l2(1e-5))(melgram_input)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(N_MEL_BANDS, SEGMENT_DUR/maxpool_const))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(n_classes, kernel_initializer='zeros', kernel_regularizer=l2(1e-5), \n",
    "              activation='softmax', name='prediction')(x)\n",
    "\n",
    "    model = Model(melgram_input, x)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(IRMAS_N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the model on IRMAS data using the training procedure below.\n",
    "\n",
    "First, we have to define the optimizer. We're using Stochastic Gradient Descent with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_lr = 0.001\n",
    "optimizer = SGD(lr=init_lr, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the model structure, specify which metrics we would like to keep eye on and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 96, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 96, 128, 64)       13504     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 96, 128, 64)       256       \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 96, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 11)                2827      \n",
      "=================================================================\n",
      "Total params: 16,587\n",
      "Trainable params: 16,459\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous part, we have two generators which can provide us training samples and validation samples. \n",
    "We will use them during the training. We also specify the number of steps per epoch, the total number of epoch and the log verbosity level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(),\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    nb_epoch=MAX_EPOCH_NUM,\n",
    "                    verbose=2,\n",
    "                    validation_data=val_generator(),\n",
    "                    class_weight=None,\n",
    "                    nb_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, neither validation nor the training metrics has improved, so we need to explore that's wrong with the model. Keras Callbacks will help us in this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Callbacks\n",
    "\n",
    "The Callback in Keras is a set of functions to be applied on a certain event during the training process.\n",
    "The typical triggers for events are:\n",
    "* on_epoch_begin\n",
    "* on_epoch_end\n",
    "* on_batch_begin\n",
    "* on_batch_end\n",
    "* on_train_begin\n",
    "* on_train_end\n",
    "\n",
    "There are some useful callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_EPOCH)\n",
    "save_clb = ModelCheckpoint(\"{weights_basepath}/\".format(weights_basepath=MODEL_WEIGHT_BASEPATH) +\n",
    "                           \"epoch.{epoch:02d}-val_loss.{val_loss:.3f}\",\n",
    "                           monitor='val_loss',\n",
    "                           save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get acquainted with the TensorBoard Callback.\n",
    "\n",
    "The parameters are:\n",
    "* log_dir - where to store the logs, metadata, and events of the model training process\n",
    "* write_graph - whether or not to write the graph of data and control dependencies\n",
    "* write_grads - whether or not to save the parameters of the model for visualisation\n",
    "* histogram_freq - how often to save the parameters of the model\n",
    "* write_images - whether or not to save the weight and visualise them as images\n",
    "\n",
    "Additional parameters includes embeddings visualisation but, as we will see, it's not suitable for our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='./example_1',\n",
    "                 write_graph=True, write_grads=True, \n",
    "                 write_images=True, histogram_freq=1)\n",
    "# if we want to compute activations and weight histogram, we need to specify the validation data for that. \n",
    "tb.validation_data = val_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the callbacks to the training process and observe the corresponding enevts and obtain the corresponding logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator(),\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    nb_epoch=MAX_EPOCH_NUM,\n",
    "                    verbose=2,\n",
    "                    validation_data=val_generator(),\n",
    "                    callbacks=[save_clb, early_stopping, tb],\n",
    "                    class_weight=None,\n",
    "                    nb_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the event files for all runs from [here](https://drive.google.com/open?id=0B6VSPXOeu5J0TnRhS18xS2pBMFU).\n",
    "\n",
    "Now create the `./logs` directory and launch TensorBoard\n",
    "\n",
    "``` bash\n",
    "tar -xvzf logs.tar.gz\n",
    "cd logs\n",
    "tensorboard --logdir ./example_1\n",
    "```\n",
    "\n",
    "and navigate to http://0.0.0.0:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice, that it's almoust impossible to see anything on the Graphs tab but we can see vividly that the metrics on the Scalar tab are not improving and the gradients values on the Histograms tab are zero.\n",
    "\n",
    "Our problem is in the weights initialization `kernel_initializer='zeros'` so now we can fix it and define new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(n_classes):\n",
    "\n",
    "    input_shape = (N_MEL_BANDS, SEGMENT_DUR, 1)\n",
    "    channel_axis = 3\n",
    "    melgram_input = Input(shape=input_shape)\n",
    "\n",
    "    m_size = 70\n",
    "    n_size = 3\n",
    "    n_filters = 64\n",
    "    maxpool_const = 4\n",
    "\n",
    "    x = Convolution2D(n_filters, (m_size, n_size),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(1e-5))(melgram_input)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(N_MEL_BANDS, SEGMENT_DUR/maxpool_const))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(n_classes, kernel_initializer='he_normal', kernel_regularizer=l2(1e-5), \n",
    "              activation='softmax', name='prediction')(x)\n",
    "\n",
    "    model = Model(melgram_input, x)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(IRMAS_N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you will repeate the training process, you may notice that classification performance improved significantly.\n",
    "\n",
    "Have a look for a new log file in the `./example_2` directory and restart TensorBoard to explore new data.\n",
    "\n",
    "``` bash\n",
    "cd logs\n",
    "tensorboard --logdir ./example_2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow name scopes\n",
    "\n",
    "You might have noticed the hell on the Graphs tab.\n",
    "That's because TensorBoard can't connect all the data nodes in the model and operations in the training process together, it's smart enought to group the nodes with similar structure but don't expect too much.\n",
    "\n",
    "In order to make the better graph visualisation, we need to define the name scopes for each logical layer and each operation we want to see as an individual element.\n",
    "\n",
    "We can do it just by adding `with tf.name_scope(name_scope)` clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_namescope = 'train'\n",
    "\n",
    "def build_model(n_classes):\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        input_shape = (N_MEL_BANDS, SEGMENT_DUR, 1)\n",
    "        channel_axis = 3\n",
    "        melgram_input = Input(shape=input_shape)\n",
    "\n",
    "        m_size = [5, 5]\n",
    "        n_size = [5, 5]\n",
    "        n_filters = 64\n",
    "        maxpool_const = 8\n",
    "\n",
    "    with tf.name_scope('conv1'):\n",
    "        x = Convolution2D(n_filters, (m_size[0], n_size[0]),\n",
    "                          padding='same',\n",
    "                          kernel_initializer='he_uniform')(melgram_input)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        x = ELU()(x)\n",
    "        x = MaxPooling2D(pool_size=(maxpool_const, maxpool_const))(x)\n",
    "\n",
    "    with tf.name_scope('conv2'):\n",
    "        x = Convolution2D(n_filters*2, (m_size[1], n_size[1]),\n",
    "                          padding='same',\n",
    "                          kernel_initializer='he_uniform')(x)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        x = ELU()(x)\n",
    "        x = MaxPooling2D(pool_size=(maxpool_const, maxpool_const))(x)\n",
    "        x = Flatten()(x)\n",
    "\n",
    "    with tf.name_scope('dense1'):\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(n_filters, kernel_initializer='he_uniform', name='hidden')(x)\n",
    "        x = ELU()(x)\n",
    "\n",
    "    with tf.name_scope('dense2'):\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(n_classes, kernel_initializer='he_uniform', activation='softmax', name='prediction')(x)\n",
    "\n",
    "    model = Model(melgram_input, x)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(IRMAS_N_CLASSES)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = SGD(lr=init_lr, momentum=0.9, nesterov=True)\n",
    "\n",
    "with tf.name_scope('model'):\n",
    "    model = build_model(IRMAS_N_CLASSES)\n",
    "\n",
    "# for the sake of memory, only graphs now\n",
    "with tf.name_scope('callbacks'):\n",
    "    # The TensorBoard developers are strongly encourage us to use different directories for every run\n",
    "    tb = TensorBoard(log_dir='./example_3', write_graph=True)\n",
    "\n",
    "# yes, we need to recompile the model every time\n",
    "with tf.name_scope('compile'):\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# and preudo-train the model\n",
    "with tf.name_scope(global_namescope):\n",
    "    model.fit_generator(train_generator(),\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        nb_epoch=1, # one epoch to save the graphs\n",
    "                        verbose=2,\n",
    "                        validation_data=val_generator(),\n",
    "                        callbacks=[tb],\n",
    "                        nb_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look for a new log file in the `./example_3` directory and restart TensorBoard to explore new data.\n",
    "\n",
    "``` bash\n",
    "cd logs\n",
    "tensorboard --logdir ./example_3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Visualisation\n",
    "\n",
    "With TensorBoard we can also visualise the embeddings of the model.\n",
    "Unfortunately, the present implementation in Keras doesn't allow to store the true embeddings on the data (it only saves weights for the layers _or_ embeddings for the Embedding layers, that is siutable for word embeddings like word2vec, but is not suitable in our case). \n",
    "\n",
    "However, we can write our custom callback and use it to store the embeddings on validation data during the training process. We will follow the notation from TensorBoard callback, but add some functionality:\n",
    "\n",
    "* layer_names - a list of names of layers to keep eye on\n",
    "* metadata - a path to a TSV file with associated meta information (labels, notes, etc.), [format and details](https://www.tensorflow.org/get_started/embedding_viz) \n",
    "* sprite - a path to a sprite image, [format and details](https://www.tensorflow.org/get_started/embedding_viz) \n",
    "* sprite_shape - a list with values [M, N], the dimentionality of a single image, [format and details](https://www.tensorflow.org/get_started/embedding_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorBoardEmbeddings(Callback):\n",
    "    \"\"\"Tensorboard Embeddings visualization callback.\"\"\"\n",
    "\n",
    "    def __init__(self, log_dir='./logs_embed',\n",
    "                 batch_size=32,\n",
    "                 freq=0,\n",
    "                 layer_names=None,\n",
    "                 metadata=None,\n",
    "                 sprite=None,\n",
    "                 sprite_shape=None):\n",
    "        super(TensorEmbeddings, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.freq = freq\n",
    "        self.layer_names = layer_names\n",
    "        # Notice, that only one file is supported in the present callback\n",
    "        self.metadata = metadata\n",
    "        self.sprite = sprite\n",
    "        self.sprite_shape = sprite_shape\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        self.summary_writer = tf.summary.FileWriter(self.log_dir)\n",
    "        self.embeddings_ckpt_path = os.path.join(self.log_dir, 'keras_embedding.ckpt')\n",
    "\n",
    "        if self.freq and self.validation_data:\n",
    "            # define tensors to compute embeddings on\n",
    "            embeddings_layers = [layer for layer in self.model.layers\n",
    "                                 if layer.name in self.layer_names]\n",
    "            self.output_tensors = [tf.get_default_graph().get_tensor_by_name(layer.get_output_at(0).name)\n",
    "                                   for layer in embeddings_layers]\n",
    "\n",
    "            # create configuration for embeddings visualisation\n",
    "            config = projector.ProjectorConfig()\n",
    "            for i in range(len(self.output_tensors)):\n",
    "                embedding = config.embeddings.add()\n",
    "                embedding.tensor_name = '{ns}/embedding_{i}'.format(ns=global_namescope, i=i)\n",
    "\n",
    "                # Simpliest metadata handler, a single file for all embeddings\n",
    "                if self.metadata:\n",
    "                    embedding.metadata_path = self.metadata\n",
    "\n",
    "                # Sprite image handler\n",
    "                if self.sprite and self.sprite_shape:\n",
    "                    embedding.sprite.image_path = self.sprite\n",
    "                    embedding.sprite.single_image_dim.extend(self.sprite_shape)\n",
    "\n",
    "            # define TF variables to store the embeddings during the training\n",
    "            # Notice, that only 1D embeddings are supported\n",
    "            self.embedding_vars = [tf.Variable(np.zeros((len(self.validation_data[0]),\n",
    "                                                         self.output_tensors[i].shape[1]),\n",
    "                                                        dtype='float32'),\n",
    "                                               name='embedding_{}'.format(i))\n",
    "                                   for i in range(len(self.output_tensors))]\n",
    "            # add TF variables into computational graph\n",
    "            for embedding_var in self.embedding_vars:\n",
    "                self.sess.run(embedding_var.initializer)\n",
    "\n",
    "            # save the config and setup TF saver for embedding variables\n",
    "            projector.visualize_embeddings(self.summary_writer, config)\n",
    "            self.saver = tf.train.Saver(self.embedding_vars)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data and self.freq:\n",
    "            if epoch % self.freq == 0:\n",
    "\n",
    "                val_data = self.validation_data\n",
    "                tensors = (self.model.inputs +\n",
    "                           self.model.targets +\n",
    "                           self.model.sample_weights)\n",
    "                all_embeddings = [[]]*len(self.output_tensors)\n",
    "\n",
    "                if self.model.uses_learning_phase:\n",
    "                    tensors += [K.learning_phase()]\n",
    "\n",
    "                assert len(val_data) == len(tensors)\n",
    "                val_size = val_data[0].shape[0]\n",
    "                i = 0\n",
    "                # compute embeddings batch by batch on validation data\n",
    "                while i < val_size:\n",
    "                    step = min(self.batch_size, val_size - i)\n",
    "                    batch_val = []\n",
    "                    batch_val.append(val_data[0][i:i + step])\n",
    "                    batch_val.append(val_data[1][i:i + step])\n",
    "                    batch_val.append(val_data[2][i:i + step])\n",
    "                    if self.model.uses_learning_phase:\n",
    "                        batch_val.append(val_data[3])\n",
    "                    feed_dict = dict(zip(tensors, batch_val))\n",
    "                    tensor_outputs = self.sess.run(self.output_tensors, feed_dict=feed_dict)\n",
    "                    for output_idx, tensor_output in enumerate(tensor_outputs):\n",
    "                        all_embeddings[output_idx].extend(tensor_output)\n",
    "                    i += self.batch_size\n",
    "                \n",
    "                # rewrite the current state of embeddings with new values\n",
    "                for embedding_idx, embed in enumerate(self.embedding_vars):\n",
    "                    embed.assign(np.array(all_embeddings[embedding_idx])).eval(session=self.sess)\n",
    "                # save embedding variables (the saver is defied above, so it knows what to store)\n",
    "                self.saver.save(self.sess, self.embeddings_ckpt_path, epoch)\n",
    "\n",
    "        self.summary_writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add the new callback, recompile and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_to_monitor = ['hidden']\n",
    "# find the files precomputed in ./logs_embed directory \n",
    "metadata_file_name = 'metadata.tsv'\n",
    "sprite_file_name = 'sprite.png'\n",
    "sprite_shape = [N_MEL_BANDS, SEGMENT_DUR]\n",
    "\n",
    "with tf.name_scope('callbacks'):\n",
    "    tbe = TensorBoardEmbeddings(log_dir='./logs_embed', freq=1,\n",
    "                           layer_names=embeddings_to_monitor,\n",
    "                           metadata=metadata_file_name,\n",
    "                           sprite=sprite_file_name,\n",
    "                           sprite_shape=sprite_shape)\n",
    "    tbe.validation_data = val_generator()\n",
    "\n",
    "with tf.name_scope('compile'):\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "with tf.name_scope(global_namescope):\n",
    "    model.fit_generator(train_generator(),\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        nb_epoch=MAX_EPOCH_NUM,\n",
    "                        verbose=2,\n",
    "                        callbacks=[tbe],\n",
    "                        validation_data=val_generator(),\n",
    "                        class_weight=None,\n",
    "                        nb_worker=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of time, we're going to skip the trainig process. You can find the corresponding data in `./logs_embed` directory.\n",
    "\n",
    "Restart TensorBoard, navigate to http://0.0.0.0:6006/ and now we can discuss the embeddings in details.\n",
    "``` bash\n",
    "cd logs\n",
    "tensorboard --logdir ./logs_embed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
